{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6fb47f14ad3f2b",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" />\n",
    "\n",
    "# Cours TAL – Labo 5 : Le modèle word2vec et ses applications\n",
    "\n",
    "**Objectifs**\n",
    "Le but de ce labo est de comparer un modèle word2vec pré-entraîné avec deux modèles que vous\n",
    "entraînerez vous-mêmes, sur deux corpus de tailles différentes. La comparaison se fera sur une\n",
    "tâche de similarité mots et sur une tâche de raisonnement par analogie, en anglais. Vous utiliserez la librairie Gensim de calcul de similarités pour le TAL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6433de2c0ea02",
   "metadata": {},
   "source": [
    "## 1. Tester et évaluer un modèle déjà entraîné sur Google News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423906f83dc53276",
   "metadata": {},
   "source": [
    "Installez gensim, une librairie Python qui fournit des outils pour travailler avec Word2Vec (avec\n",
    "conda ou avec pip). **Attention** : la dernière version 4.2.3 de gensim est incompatible avec la\n",
    "librairie scipy version 1.13, donc il faut installer la version 1.12 de scipy ; la variable Path doit\n",
    "contenir `C:\\ProgramData\\Miniconda3\\Library\\` et `C:\\ProgramData\\Miniconda3\\Library\\bin\\.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6c59159e137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72534b37990fc0d5",
   "metadata": {},
   "source": [
    "Obtenez depuis gensim le modèle word2vec pré-entraîné sur le corpus Google News en\n",
    "écrivant : `w2v_vectors = gensim.downloader.load(\"word2vec-google-news-300\")`, ce qui\n",
    "téléchargera le fichier la première fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be156bbd241d753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T15:23:46.073306Z",
     "start_time": "2024-05-06T15:19:39.208992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "#Default path is C:\\Users\\username\\gensim-data\n",
    "w2v_vectors = gensim.downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074e79c7f1e5dd2",
   "metadata": {},
   "source": [
    "Après avoir téléchargé le modèle, vous pouvez utiliser ainsi votre copie locale :\n",
    "`w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)`."
   ]
  },
  {
   "cell_type": "code",
   "id": "e457bc17a2a661b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:27:16.820801Z",
     "start_time": "2024-05-10T12:26:48.024507Z"
    }
   },
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"./corpus/GoogleNews-vectors-negative300.bin\", binary=True)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "2f61e9cd95680235",
   "metadata": {},
   "source": [
    "#### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "\n",
    "Nous installant l'extension jupyter-server-resource-usage, nous avons pu observer que le kernel du notebook occupait 2.8 Go de mémoire vive après le chargement du modèle téléchargé en amont\n",
    "\n",
    "![](./img/memory_usage.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### b. Quelle est la dimension de l'espace vectoriel dans lequel les mots sont représentés ?\n",
    "\n"
   ],
   "id": "faf7e6d0354573e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:27:24.705620Z",
     "start_time": "2024-05-10T12:27:24.686949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(w2v_vectors.key_to_index.__len__()) #Nombre de clés = nombre de mots\n",
    "print(w2v_vectors.vector_size) #Taille du vecteur pour chaque clé"
   ],
   "id": "1c78f7fcf0a0e6c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "300\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un `KeyedVector` est une structure semblable à un dictionnaire ayant comme clé un mot et comme valeur un vecteur. Dans notre cas, nous avons 3000000 clés chacune ayant un vecteur de 300 entrées.",
   "id": "cef78bc59595f4e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher 5 mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.",
   "id": "357186367ef7c490"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:27:27.101141Z",
     "start_time": "2024-05-10T12:27:26.502346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "voc_model = set(w2v_vectors.index_to_key)\n",
    "result_in_voc = {\"hello\", \"world\", \"computer\", \"science\", \"data\"}.intersection(voc_model)\n",
    "result_not_in_voc = {\"crapulous\", \"manichaean\"}.difference(voc_model)\n",
    "\n",
    "print(f\"Mots dans le vocabulaire {result_in_voc}\") #5 mots\n",
    "print(f\"Mots pas dans le vocabulaire {result_not_in_voc}\")\n",
    "print(f\"taille du vocabulaire {len(voc_model)}\")"
   ],
   "id": "69b7320423527fb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots dans le vocabulaire {'computer', 'science', 'hello', 'data', 'world'}\n",
      "Mots pas dans le vocabulaire {'crapulous', 'manichaean'}\n",
      "taille du vocabulaire 3000000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### d. Quelle est la distance entre les mots rabbit et carrot ? Veuillez expliquer en une phrase comment on mesure les distances entre deux mots grâce à leurs vecteurs",
   "id": "4379e37ed5ef8f62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:27:32.785346Z",
     "start_time": "2024-05-10T12:27:32.769040Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Distance entre les mots: \", w2v_vectors.distance(\"rabbit\", \"carrot\"))",
   "id": "6d14ec0409261808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre les mots:  0.6369356513023376\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "La distance entre deux mots est mesurée par la similarité cosinus entre les vecteurs de ces mots. Plus la valeur est proche de 0, plus les mots sont similaires, plus la valeur est proche de 1, plus les mots sont différents.",
   "id": "a9b0b0a2a471bbcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la distance entre les deux mots. Veuillez indiquer si les distances obtenues correspondent à vos intuitions sur la proximité des sens des mots.",
   "id": "a44966e9a771541"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:27:38.133374Z",
     "start_time": "2024-05-10T12:27:38.115259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs = [(\"cat\", \"dog\"), (\"cat\", \"car\"), (\"hot\", \"cold\"), (\"shoe\", \"journalist\"), (\"height\", \"high\")]\n",
    "\n",
    "for pair in pairs:\n",
    "    print(f\"Distance entre les mots {pair}: \", w2v_vectors.distance(pair[0], pair[1]))\n",
    "    "
   ],
   "id": "e1ad03cea7f5eac2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre les mots ('cat', 'dog'):  0.23905426263809204\n",
      "Distance entre les mots ('cat', 'car'):  0.7847181558609009\n",
      "Distance entre les mots ('hot', 'cold'):  0.5397861003875732\n",
      "Distance entre les mots ('shoe', 'journalist'):  0.8940958231687546\n",
      "Distance entre les mots ('height', 'high'):  0.8072148114442825\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **('cat', 'dog'):** Il s'agit de deux animaux de compagnie souvent mis en comparaison ou en opposition. Le score étant faible, il est cohérent avec notre intuition.\n",
    "- **('cat', 'car'):** Ces deux mots sont proches au sens de l'orthographe, mais n'ont pas forcément un lien sémantique fort. On pourrait éventuellement supposer une distance faible si le système prenait en compte les erreurs typographiques, étant donné que T et R sont à côté l'un de l'autre sur un clavier QWERTY, mais ce n'est pas le cas. Le score étant élevé, il est cohérent avec notre intuition.\n",
    "- **('hot', 'cold'):** Il s'agit de deux antonymes, ils possèdent donc un même sens sémantique (la température), mais leur nature d'antonymes pourrait également les éloigner. Le score est relativement moyen (~0.5) ce qui confirme notre intuition\n",
    "- **('shoe', 'journalist'):** Ces deux mots n'ont rien en commun, on s'attend à un score élevé, ce qui est le cas.\n",
    "- **('height', 'high'):** Ces deux mots sont similaires (l'un étant l'adjectif de l'autre), on s'attendrait à un score proche, voir moyen, mais le score est beaucoup plus élevé que notre intuition"
   ],
   "id": "30e856fb4b8d3db8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?",
   "id": "ca73bd0afbc84a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:28:34.351725Z",
     "start_time": "2024-05-10T12:27:43.534978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Top 10 des mots les plus similaire: \", w2v_vectors.most_similar(\"good\", topn=10))\n",
    "print(f\"Distance entre 'good' et 'bad': \", w2v_vectors.distance(\"good\", \"bad\"))"
   ],
   "id": "bf322ad1255aaa77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 des mots les plus similaire:  [('great', 0.7291510105133057), ('bad', 0.7190051078796387), ('terrific', 0.6889115571975708), ('decent', 0.6837348341941833), ('nice', 0.6836092472076416), ('excellent', 0.644292950630188), ('fantastic', 0.6407778263092041), ('better', 0.6120728850364685), ('solid', 0.5806034803390503), ('lousy', 0.576420247554779)]\n",
      "Distance entre 'good' et 'bad':  0.28099489212036133\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Le mot \"good\" est proche de \"bad\" dans le modèle word2vec, ce qui est surprenant car ces deux mots sont des antonymes. Cela peut s'expliquer par le fait que les mots \"good\" et \"bad\" sont souvent utilisés dans des contextes similaires, par exemple dans des critiques de films ou de restaurants. C'est un défaut du modèle word2vec, car il ne prend pas en compte le sens des mots, mais seulement leur fréquence d'apparition dans un corpus de texte.",
   "id": "8a51de7838a7ba75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### g. calculez le score du modèle word2vec sur les données WordSimilarity-353. Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure.",
   "id": "a1587463e9b77d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:29:02.483243Z",
     "start_time": "2024-05-10T12:29:01.645374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "\n",
    "pearson, spearman, oov_ration = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(pearson)\n",
    "print(spearman)\n",
    "print(oov_ration)"
   ],
   "id": "756acc45f3ec9872",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.6238773472434951, pvalue=1.7963233960134136e-39)\n",
      "SignificanceResult(statistic=0.6589215888009288, pvalue=2.5346056459149263e-45)\n",
      "0.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le score de Pearson et le score de Spearman mesurent la corrélation entre les similarités de mots prédites par le modèle et les similarités de mots humaines (score de référence).\n",
    "Le score de Pearson est une mesure de la corrélation linéaire entre deux variables, tandis que le score de Spearman est une mesure de la corrélation monotone. Un score élevé indique que le modèle prédit bien les similarités de mots humaines.\n",
    "La pvalue est une valeur indiquant si le coefficient statistique est calculé par hasard. Plus cette valeur est faible, plus la corrélation statistique est significative (c.à.d. que la corrélation n'est pas due au hasard)."
   ],
   "id": "37fdf636bf9673f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### h. calculez le score du modèle word2vec sur les données questions-words.txt. Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure.",
   "id": "b9fb1934604224ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T12:37:19.178893Z",
     "start_time": "2024-05-10T12:29:06.900861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "score, section = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'), dummy4unknown=True)\n",
    "print(score)"
   ],
   "id": "1753348fd519aa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7320405239459681\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On évalue ici l'analogie du modèle par rapport à certains mots dans certaines catégories de la façon suivante \"a est à b ce que c est à d\". Par exemple: \"Athène est à la Grèce ce que Paris est à la France\". Le modèle doit donc trouver le mot manquant d dans la phrase. Le score est calculé en fonction du nombre de réponses correctes trouvées par le modèle.",
   "id": "2c6d9f3045306dab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
