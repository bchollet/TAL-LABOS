{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cours TAL – Labo 7 : Classification de dépêches d’agence avec NLTK\n",
    "\n",
    "**Objectifs**\n",
    "L’objectif de ce labo est de réaliser des expériences de classification de documents avec la boîte à\n",
    "outils NLTK sur le corpus de dépêches Reuters. Le labo est à effectuer en binôme. Le rendu sera un\n",
    "notebook Jupyter présentant vos choix, votre code, vos résultats et les discussions. Le labo sera jugé\n",
    "sur la qualité des expériences et sur la discussion des différentes options explorées.\n"
   ],
   "id": "d05550221f1a3159"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Récupération des données\n",
    "\n",
    "**Données :** les dépêches du corpus Reuters, tel qu’il est fourni par NLTK. Veuillez respecter la\n",
    "division en données d’entraînement et données de test."
   ],
   "id": "71bdbbc171040120"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:02:20.292719Z",
     "start_time": "2024-06-08T13:02:06.687100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk.download('reuters')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Nous faisons le choix de traiter tous les mots en minuscule\n",
    "documents = [(list(w.lower() for w in reuters.words(fileid)), category)\n",
    "             for category in reuters.categories()\n",
    "             for fileid in reuters.fileids(category)]\n",
    "\n",
    "# documents une les stops words retirés\n",
    "documents_no_stop_words = [(list(w.lower() for w in filter(lambda w: w.lower() not in stop_words, reuters.words(fileid))), category)\n",
    "             for category in reuters.categories()\n",
    "             for fileid in reuters.fileids(category)]\n",
    "\n",
    "# documents après lemmatisation des mots\n",
    "documents_lemmatized = [(list(w.lower() for w in map(lemmatizer.lemmatize, reuters.words(fileid))), category)\n",
    "             for category in reuters.categories()\n",
    "             for fileid in reuters.fileids(category)]"
   ],
   "id": "b5feb182f989dfe3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:02:25.429468Z",
     "start_time": "2024-06-08T13:02:22.681228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Récupère la fréquence des mots en filtrant les mots de moins de 4 caractères (évite l'apprentissage sur des symboles ou abréviations)\n",
    "import re\n",
    "all_words = nltk.FreqDist(w.lower() for w in reuters.words() if re.match(r'^[a-z]{3,}$', w))\n",
    "\n",
    "# On sélectionne les 2000 mots les plus fréquents comme features pour les classifieurs\n",
    "word_features = list(all_words)[:2000]"
   ],
   "id": "a5b19d4772d21d95",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:31:15.109483Z",
     "start_time": "2024-06-08T13:31:15.102992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "# Modifie les catégories des documents pour les rendre binaires\n",
    "def documents_with_binary_category(documents, category):\n",
    "    return [(d, category if c == category else 'other') for (d, c) in documents]\n",
    "\n",
    "# Modifie les catégories des documents pour limiter les catégories à celles passées en paramètre\n",
    "def documents_with_retrcted_categories(documents, categories):\n",
    "    return [(d, category if category in categories else 'other') for (d, category) in documents]\n",
    "\n",
    "# split un dataset en 80% train et 20% test pour chaque category\n",
    "def split_dataset(documents):\n",
    "    dataset = {}\n",
    "    for (d, c) in documents:\n",
    "        if c not in dataset:\n",
    "            dataset[c] = []\n",
    "        dataset[c].append(d)\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for c in dataset:\n",
    "        random.shuffle(dataset[c])\n",
    "        train_set += [(d, c) for d in dataset[c][int(len(dataset[c]) * 0.2):]]\n",
    "        test_set += [(d, c) for d in dataset[c][:int(len(dataset[c]) * 0.2)]]\n",
    "    return train_set, test_set\n",
    "\n",
    "# Retourne un dictionnaire indiquant si une feature est présent dans le document\n",
    "def document_contains_features(document):\n",
    "    doc_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in doc_words)\n",
    "    return features\n",
    "\n",
    "def get_featuresets(documents):\n",
    "    return [(document_contains_features(d), c) for (d,c) in documents]\n",
    "\n",
    "# Retourne la précision, le rappel et le F-score pour un classifieur sur un test set donné\n",
    "def print_scores_for_category(classifier, test_set, category):\n",
    "    classifier_labels = classifier.classify_many(tup[0] for tup in test_set)\n",
    "    reference_labels = [tup[1] for tup in test_set]\n",
    "    \n",
    "    docs_in_cat = len([l for l in reference_labels if l == category])\n",
    "    docs_classified_in_cat = len([l for l in classifier_labels if l == category])\n",
    "    docs_correctly_classified_in_cat = len([i for i in range(len(reference_labels)) if reference_labels[i] == category and classifier_labels[i] == category])\n",
    "    \n",
    "    recall = docs_correctly_classified_in_cat / docs_in_cat\n",
    "    precision = docs_correctly_classified_in_cat / docs_classified_in_cat\n",
    "    f_score = 2 * recall * precision / (recall + precision)\n",
    "    \n",
    "    print('Rappel:', recall)\n",
    "    print('Précision:', precision)\n",
    "    print('F-mesure:', f_score)"
   ],
   "id": "b5a572e49a72875f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Classifieurs binaires\n",
    "\n",
    "## 2.1 Classifieur binaire pour la catégorie 'money-fx'\n",
    "\n",
    "### 2.1.1 Classifieur Bayésien naïf + lemmatisation"
   ],
   "id": "19ce11ccb64d7b14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:21:42.969943Z",
     "start_time": "2024-06-08T12:21:27.785971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_moneyfx_lemmatized = documents_with_binary_category(documents_lemmatized, 'money-fx')\n",
    "\n",
    "train_set_moneyfx_lemmatized, test_set_moneyfx_lemmatized = split_dataset(get_featuresets(dataset_moneyfx_lemmatized))\n",
    "\n",
    "classifier_moneyfx_lemmatized = nltk.NaiveBayesClassifier.train(train_set_moneyfx_lemmatized)"
   ],
   "id": "188ade5762dff722",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:27:19.170512Z",
     "start_time": "2024-06-08T12:27:14.156468Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_moneyfx_lemmatized, test_set_moneyfx_lemmatized, 'money-fx')",
   "id": "cf27b2aebbbb52f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.7832167832167832\n",
      "Précision: 0.3163841807909605\n",
      "F-mesure: 0.4507042253521127\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1.2 Classifieur Bayésien naïf + stops words retirés",
   "id": "10e693a2067a1d9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:28:17.222552Z",
     "start_time": "2024-06-08T12:28:02.271690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_moneyfx_no_stop_words = documents_with_binary_category(documents_no_stop_words, 'money-fx')\n",
    "\n",
    "train_set_moneyfx_no_stop_words, test_set_moneyfx_no_stop_words = split_dataset(get_featuresets(dataset_moneyfx_no_stop_words))\n",
    "\n",
    "classifier_moneyfx_no_stop_words = nltk.NaiveBayesClassifier.train(train_set_moneyfx_no_stop_words)"
   ],
   "id": "86292fd63990c291",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:28:32.320862Z",
     "start_time": "2024-06-08T12:28:27.061672Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_moneyfx_no_stop_words, test_set_moneyfx_no_stop_words, 'money-fx')",
   "id": "fe4a0c05a4905b69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.6993006993006993\n",
      "Précision: 0.32786885245901637\n",
      "F-mesure: 0.4464285714285714\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Classifieur binaire pour la catégorie 'grain'\n",
    "### 2.2.1 Classifieur Bayésien naïf + lemmatisation"
   ],
   "id": "90f606ff0fc31803"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:30:24.845404Z",
     "start_time": "2024-06-08T12:30:10.263032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_grain_lemmatized = documents_with_binary_category(documents_lemmatized, 'grain')\n",
    "\n",
    "train_set_grain_lemmatized, test_set_grain_lemmatized = split_dataset(get_featuresets(dataset_grain_lemmatized))\n",
    "\n",
    "classifier_grain_lemmatized = nltk.NaiveBayesClassifier.train(train_set_grain_lemmatized)"
   ],
   "id": "91b80a217a751f2a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:30:34.979774Z",
     "start_time": "2024-06-08T12:30:29.735228Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_grain_lemmatized, test_set_grain_lemmatized, 'grain')",
   "id": "6c5148c3b4aa5214",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.75\n",
      "Précision: 0.22250639386189258\n",
      "F-mesure: 0.3431952662721894\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2.2 Classifieur Bayésien naïf + stops words retirés",
   "id": "2059fb5bdddb7436"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:31:24.009759Z",
     "start_time": "2024-06-08T12:31:09.177689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_grain_no_stop_words = documents_with_binary_category(documents_no_stop_words, 'grain')\n",
    "\n",
    "train_set_grain_no_stop_words, test_set_grain_no_stop_words = split_dataset(get_featuresets(dataset_grain_no_stop_words))\n",
    "\n",
    "classifier_grain_no_stop_words = nltk.NaiveBayesClassifier.train(train_set_grain_no_stop_words)"
   ],
   "id": "2f526fe326e373eb",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:31:43.722689Z",
     "start_time": "2024-06-08T12:31:38.428836Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_grain_no_stop_words, test_set_grain_no_stop_words, 'grain')",
   "id": "f5c2a8f86ed6da3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.853448275862069\n",
      "Précision: 0.24812030075187969\n",
      "F-mesure: 0.3844660194174757\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Classifieur binaire pour la catégorie 'nat-gas'\n",
    "### 2.3.1 Classifieur Bayésien naïf + lemmatisation "
   ],
   "id": "283baf343b621ae7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:35:17.189407Z",
     "start_time": "2024-06-08T12:35:02.450696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_natgas_lemmatized = documents_with_binary_category(documents_lemmatized, 'nat-gas')\n",
    "\n",
    "train_set_natgas_lemmatized, test_set_natgas_lemmatized = split_dataset(get_featuresets(dataset_natgas_lemmatized))\n",
    "\n",
    "classifier_natgas_lemmatized = nltk.NaiveBayesClassifier.train(train_set_natgas_lemmatized)"
   ],
   "id": "50c89f2e46b475f9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:35:23.988184Z",
     "start_time": "2024-06-08T12:35:18.686845Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_natgas_lemmatized, test_set_natgas_lemmatized, 'nat-gas')",
   "id": "baab5c0b7084099",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.5238095238095238\n",
      "Précision: 0.05188679245283019\n",
      "F-mesure: 0.09442060085836909\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3.2 Classifieur Bayésien naïf + stops words retirés",
   "id": "8ad3bac17a824f1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:36:10.071964Z",
     "start_time": "2024-06-08T12:35:55.300422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_natgas_no_stop_words = documents_with_binary_category(documents_no_stop_words, 'nat-gas')\n",
    "\n",
    "train_set_natgas_no_stop_words, test_set_natgas_no_stop_words = split_dataset(get_featuresets(dataset_natgas_no_stop_words))\n",
    "\n",
    "classifier_natgas_no_stop_words = nltk.NaiveBayesClassifier.train(train_set_natgas_no_stop_words)"
   ],
   "id": "6c44b5d765041c32",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T12:36:22.675282Z",
     "start_time": "2024-06-08T12:36:17.412727Z"
    }
   },
   "cell_type": "code",
   "source": "print_scores_for_category(classifier_natgas_no_stop_words, test_set_natgas_no_stop_words, 'nat-gas')",
   "id": "476c10d4ee45b8df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rappel: 0.6190476190476191\n",
      "Précision: 0.1\n",
      "F-mesure: 0.17218543046357618\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.4 Observations\n",
    "\n",
    "Le dataset pré-traité en retirant les stops words semble donner de meilleurs résultats que le dataset pré-traité en lemmatisant les mots. Cela peut s'expliquer par le fait que les stops words sont des mots très fréquents qui n'apportent pas d'information utile pour la classification. En les retirant, on peut donc s'attendre à ce que le classifieur se concentre sur des mots plus significatifs pour la classification, car ils ne seront plus présent dans le featureset."
   ],
   "id": "7010e04bc3506064"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Classifieur multi-classes\n",
    "## 3.1 Classifier Bayésien naïf + stop words retirés"
   ],
   "id": "555c3a9432002cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:31:52.925029Z",
     "start_time": "2024-06-08T13:31:38.293700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "documents_multi = documents_with_retrcted_categories(documents_no_stop_words, ['money-fx', 'grain', 'nat-gas'])\n",
    "\n",
    "train_set_multi, test_set_multi = split_dataset(get_featuresets(documents_multi))\n",
    "\n",
    "classifier_multi = nltk.NaiveBayesClassifier.train(train_set_multi)"
   ],
   "id": "e67bbd89475813e6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:32:08.696901Z",
     "start_time": "2024-06-08T13:31:59.466928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Résultats pour la catégorie money-fx:')\n",
    "print_scores_for_category(classifier_multi, test_set_multi, 'money-fx')"
   ],
   "id": "21c733e437f6ba03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour la catégorie money-fx:\n",
      "Rappel: 0.7412587412587412\n",
      "Précision: 0.3569023569023569\n",
      "F-mesure: 0.4818181818181818\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:32:23.422305Z",
     "start_time": "2024-06-08T13:32:14.195160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Résultats pour la catégorie grain:')\n",
    "print_scores_for_category(classifier_multi, test_set_multi, 'grain')"
   ],
   "id": "5bb857eb5fa7e11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour la catégorie grain:\n",
      "Rappel: 0.7844827586206896\n",
      "Précision: 0.23697916666666666\n",
      "F-mesure: 0.364\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:32:34.638386Z",
     "start_time": "2024-06-08T13:32:25.403094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Résultats pour la catégorie nat-gas:')\n",
    "print_scores_for_category(classifier_multi, test_set_multi, 'nat-gas')"
   ],
   "id": "648d543fc8d0680e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats pour la catégorie nat-gas:\n",
      "Rappel: 0.6190476190476191\n",
      "Précision: 0.1092436974789916\n",
      "F-mesure: 0.1857142857142857\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Conclusion\n",
    "\n",
    "Comment ces scores du classifieur multi-classe se comparent-ils à ceux des trois classifieurs binaires plus haut ? Quelle est donc la meilleure stratégie de classification ?\n",
    "\n",
    "Les scores du classifieur multi-classe sont à peine plus élevé que ceux des classifieurs binaires. Cela peut s'expliquer par le fait que lors de la classification binaires, certains mots ont une probabilité similaire de se retrouver dans la classe A ou B. En rajoutant une troisième classe C, celle-ci peut définir la classe parfaite pour le mot qui tiraillait la classe A et B.\n",
    "\n",
    "Dans notre situation, la meilleure stratégie de classification réside dans une classifieur multi-classe pour un ensemble de documents pré-traités en retirant les stop-words."
   ],
   "id": "dc6b50bf9aaf2d71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
