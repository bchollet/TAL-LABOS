{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6fb47f14ad3f2b",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" />\n",
    "\n",
    "# Cours TAL – Labo 5 : Le modèle word2vec et ses applications\n",
    "\n",
    "**Objectifs**\n",
    "Le but de ce labo est de comparer un modèle word2vec pré-entraîné avec deux modèles que vous\n",
    "entraînerez vous-mêmes, sur deux corpus de tailles différentes. La comparaison se fera sur une\n",
    "tâche de similarité mots et sur une tâche de raisonnement par analogie, en anglais. Vous utiliserez la librairie Gensim de calcul de similarités pour le TAL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6433de2c0ea02",
   "metadata": {},
   "source": [
    "## 1. Tester et évaluer un modèle déjà entraîné sur Google News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423906f83dc53276",
   "metadata": {},
   "source": [
    "Installez gensim, une librairie Python qui fournit des outils pour travailler avec Word2Vec (avec\n",
    "conda ou avec pip). **Attention** : la dernière version 4.2.3 de gensim est incompatible avec la\n",
    "librairie scipy version 1.13, donc il faut installer la version 1.12 de scipy ; la variable Path doit\n",
    "contenir `C:\\ProgramData\\Miniconda3\\Library\\` et `C:\\ProgramData\\Miniconda3\\Library\\bin\\.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6c59159e137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72534b37990fc0d5",
   "metadata": {},
   "source": [
    "Obtenez depuis gensim le modèle word2vec pré-entraîné sur le corpus Google News en\n",
    "écrivant : `w2v_vectors = gensim.downloader.load(\"word2vec-google-news-300\")`, ce qui\n",
    "téléchargera le fichier la première fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6be156bbd241d753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:18.079453Z",
     "start_time": "2024-05-12T20:50:50.619656Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "#Default path is C:\\Users\\username\\gensim-data\n",
    "w2v_vectors = gensim.downloader.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074e79c7f1e5dd2",
   "metadata": {},
   "source": [
    "Après avoir téléchargé le modèle, vous pouvez utiliser ainsi votre copie locale :\n",
    "`w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)`."
   ]
  },
  {
   "cell_type": "code",
   "id": "e457bc17a2a661b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:41.201807Z",
     "start_time": "2024-05-12T20:51:18.080508Z"
    }
   },
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(\"./corpus/GoogleNews-vectors-negative300.bin\", binary=True)"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "2f61e9cd95680235",
   "metadata": {},
   "source": [
    "#### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?\n",
    "\n",
    "Nous installant l'extension jupyter-server-resource-usage, nous avons pu observer que le kernel du notebook occupait 2.8 Go de mémoire vive après le chargement du modèle téléchargé en amont\n",
    "\n",
    "![](./img/memory_usage.png)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### b. Quelle est la dimension de l'espace vectoriel dans lequel les mots sont représentés ?\n",
    "\n"
   ],
   "id": "faf7e6d0354573e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:41.210822Z",
     "start_time": "2024-05-12T20:51:41.202821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(w2v_vectors.key_to_index.__len__()) #Nombre de clés = nombre de mots\n",
    "print(w2v_vectors.vector_size) #Taille du vecteur pour chaque clé"
   ],
   "id": "1c78f7fcf0a0e6c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "300\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Un `KeyedVector` est une structure semblable à un dictionnaire ayant comme clé un mot et comme valeur un vecteur. Dans notre cas, nous avons 3000000 clés chacune ayant un vecteur de 300 entrées."
   ],
   "id": "cef78bc59595f4e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### c. Quelle est la taille du vocabulaire connu du modèle ? Veuillez afficher 5 mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas."
   ],
   "id": "357186367ef7c490"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:41.683145Z",
     "start_time": "2024-05-12T20:51:41.212949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "voc_model = set(w2v_vectors.index_to_key)\n",
    "result_in_voc = {\"hello\", \"world\", \"computer\", \"science\", \"data\"}.intersection(voc_model)\n",
    "result_not_in_voc = {\"crapulous\", \"manichaean\"}.difference(voc_model)\n",
    "\n",
    "print(f\"Mots dans le vocabulaire {result_in_voc}\") #5 mots\n",
    "print(f\"Mots pas dans le vocabulaire {result_not_in_voc}\")\n",
    "print(f\"taille du vocabulaire {len(voc_model)}\")"
   ],
   "id": "69b7320423527fb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots dans le vocabulaire {'science', 'world', 'data', 'computer', 'hello'}\n",
      "Mots pas dans le vocabulaire {'crapulous', 'manichaean'}\n",
      "taille du vocabulaire 3000000\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### d. Quelle est la distance entre les mots rabbit et carrot ? Veuillez expliquer en une phrase comment on mesure les distances entre deux mots grâce à leurs vecteurs"
   ],
   "id": "4379e37ed5ef8f62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:41.698762Z",
     "start_time": "2024-05-12T20:51:41.687311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Distance entre les mots: \", w2v_vectors.distance(\"rabbit\", \"carrot\"))"
   ],
   "id": "6d14ec0409261808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre les mots:  0.63693568110466\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "La distance entre deux mots est mesurée par la similarité cosinus entre les vecteurs de ces mots. Plus la valeur est proche de 0, plus les mots sont similaires, plus la valeur est proche de 1, plus les mots sont différents."
   ],
   "id": "a9b0b0a2a471bbcc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la distance entre les deux mots. Veuillez indiquer si les distances obtenues correspondent à vos intuitions sur la proximité des sens des mots."
   ],
   "id": "a44966e9a771541"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:41.711512Z",
     "start_time": "2024-05-12T20:51:41.702012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs = [(\"cat\", \"dog\"), (\"cat\", \"car\"), (\"hot\", \"cold\"), (\"shoe\", \"journalist\"), (\"height\", \"high\")]\n",
    "\n",
    "for pair in pairs:\n",
    "    print(f\"Distance entre les mots {pair}: \", w2v_vectors.distance(pair[0], pair[1]))\n",
    "    "
   ],
   "id": "e1ad03cea7f5eac2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance entre les mots ('cat', 'dog'):  0.23905426263809204\n",
      "Distance entre les mots ('cat', 'car'):  0.7847181558609009\n",
      "Distance entre les mots ('hot', 'cold'):  0.539786159992218\n",
      "Distance entre les mots ('shoe', 'journalist'):  0.8940958231687546\n",
      "Distance entre les mots ('height', 'high'):  0.8072148114442825\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **('cat', 'dog'):** Il s'agit de deux animaux de compagnie souvent mis en comparaison ou en opposition. Le score étant faible, il est cohérent avec notre intuition.\n",
    "- **('cat', 'car'):** Ces deux mots sont proches au sens de l'orthographe, mais n'ont pas forcément un lien sémantique fort. On pourrait éventuellement supposer une distance faible si le système prenait en compte les erreurs typographiques, étant donné que T et R sont à côté l'un de l'autre sur un clavier QWERTY, mais ce n'est pas le cas. Le score étant élevé, il est cohérent avec notre intuition.\n",
    "- **('hot', 'cold'):** Il s'agit de deux antonymes, ils possèdent donc un même sens sémantique (la température), mais leur nature d'antonymes pourrait également les éloigner. Le score est relativement moyen (~0.5) ce qui confirme notre intuition\n",
    "- **('shoe', 'journalist'):** Ces deux mots n'ont rien en commun, on s'attend à un score élevé, ce qui est le cas.\n",
    "- **('height', 'high'):** Ces deux mots sont similaires (l'un étant l'adjectif de l'autre), on s'attendrait à un score proche, voir moyen, mais le score est beaucoup plus élevé que notre intuition"
   ],
   "id": "30e856fb4b8d3db8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ? Est-ce une qualité ou un défaut du modèle word2vec ?"
   ],
   "id": "ca73bd0afbc84a5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:51:43.604487Z",
     "start_time": "2024-05-12T20:51:41.712636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Top 10 des mots les plus similaire: \", w2v_vectors.most_similar(\"good\", topn=10))\n",
    "print(f\"Distance entre 'good' et 'bad': \", w2v_vectors.distance(\"good\", \"bad\"))"
   ],
   "id": "bf322ad1255aaa77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 des mots les plus similaire:  [('great', 0.7291510105133057), ('bad', 0.7190051078796387), ('terrific', 0.6889115571975708), ('decent', 0.6837348341941833), ('nice', 0.6836092472076416), ('excellent', 0.6442928910255432), ('fantastic', 0.6407778263092041), ('better', 0.6120728850364685), ('solid', 0.5806034207344055), ('lousy', 0.5764203071594238)]\n",
      "Distance entre 'good' et 'bad':  0.28099489212036133\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le mot \"good\" est proche de \"bad\" dans le modèle word2vec, ce qui est surprenant car ces deux mots sont des antonymes. Cela peut s'expliquer par le fait que les mots \"good\" et \"bad\" sont souvent utilisés dans des contextes similaires, par exemple dans des critiques de films ou de restaurants. C'est un défaut du modèle word2vec, car il ne prend pas en compte le sens des mots, mais seulement leur fréquence d'apparition dans un corpus de texte."
   ],
   "id": "8a51de7838a7ba75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### g. calculez le score du modèle word2vec sur les données WordSimilarity-353. Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ],
   "id": "a1587463e9b77d87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:28:57.143562Z",
     "start_time": "2024-05-12T19:28:56.873463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "pearson, spearman, oov_ration = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "print(pearson)\n",
    "print(spearman)\n",
    "print(oov_ration)"
   ],
   "id": "756acc45f3ec9872",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.6238773483165634, pvalue=1.7963227018764457e-39)\n",
      "SignificanceResult(statistic=0.6589215888009288, pvalue=2.5346056459149263e-45)\n",
      "0.0\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Le score de Pearson et le score de Spearman mesurent la corrélation entre les similarités de mots prédites par le modèle et les similarités de mots humaines (score de référence).\n",
    "Le score de Pearson est une mesure de la corrélation linéaire entre deux variables, tandis que le score de Spearman est une mesure de la corrélation monotone. Un score élevé indique que le modèle prédit bien les similarités de mots humaines.\n",
    "La pvalue est une valeur indiquant si le coefficient statistique est calculé par hasard. Plus cette valeur est faible, plus la corrélation statistique est significative (c.à.d. que la corrélation n'est pas due au hasard)."
   ],
   "id": "37fdf636bf9673f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### h. calculez le score du modèle word2vec sur les données questions-words.txt. Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ],
   "id": "b9fb1934604224ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T19:40:04.413895Z",
     "start_time": "2024-05-12T19:32:43.821709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "score, section = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'), dummy4unknown=True)\n",
    "print(score)"
   ],
   "id": "1753348fd519aa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7320405239459681\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "On évalue ici l'analogie du modèle par rapport à certains mots dans certaines catégories de la façon suivante \"a est à b ce que c est à d\". Par exemple: \"Athène est à la Grèce ce que Paris est à la France\". Le modèle doit donc trouver le mot manquant d dans la phrase. Le score est calculé en fonction du nombre de réponses correctes trouvées par le modèle."
   ],
   "id": "2c6d9f3045306dab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Entraîner deux nouveaux modèles word2vec à partir de deux corpus"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c54be773b1eee3ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "a. En utilisant gensim.downloader, récupérez le corpus qui contient les 10^8 premiers caractères de Wikipédia (en anglais) avec la commande : corpus = gensim.downloader.load('text8'). Combien de phrases et de mots (tokens) possède ce corpus ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2eecaac4eb21941"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus = gensim.downloader.load('text8')\n",
    "all_docs = [d for d in corpus]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:11:24.139482Z",
     "start_time": "2024-05-12T19:11:22.610275Z"
    }
   },
   "id": "54da840b6e2694d4",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases (documents) : 1701\n",
      "Nombre de tokens : 17005207\n"
     ]
    }
   ],
   "source": [
    "count_docs = len(all_docs)\n",
    "print(f\"Nombre de phrases (documents) : {count_docs}\")\n",
    "nb_words = sum(len(l) for l in all_docs)\n",
    "print(f\"Nombre de tokens : {nb_words}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:11:26.568998Z",
     "start_time": "2024-05-12T19:11:26.564931Z"
    }
   },
   "id": "7b3820b9346e3faa",
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps que cela prend.\n",
    "• Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "• Combien de temps prend l’entraînement sur le corpus total ?\n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0b4870119e448b9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalité : 300, epochs : 50, pourcentage du corpus: 100%\n",
      "Temps d'exécution : 776.487s\n",
      "Temps d'exécution estimé si 100% du corpus était utilisé : 776.487s\n",
      "Temps d'exécution estimé si 10 epochs étaient utilisés : 155.297s\n",
      "- si 25 epochs: 388.243s\n",
      "- si 50 epochs : 776.487s\n",
      "- si 100 epochs : 1552.974s\n",
      "Temps d'exécution estimé avec 100 epochs et 100% des documents : 1552.974s \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "# Prend seulement x% des phrases du corpus\n",
    "percentage = 100\n",
    "docs_to_take = int((count_docs / (100 / percentage)))\n",
    "docs = all_docs[:docs_to_take]\n",
    "\n",
    "epochs = 50\n",
    "dimensionality = 300\n",
    "\n",
    "start = time.time()\n",
    "model = Word2Vec(sentences=docs, \n",
    "                 vector_size=dimensionality, \n",
    "                 workers=12, \n",
    "                 min_count=1,\n",
    "                 epochs=epochs)\n",
    "end = time.time()\n",
    "training_time_secs = round(end - start, 3)\n",
    "\n",
    "def estimate(projected, current):\n",
    "    return f\"{round(training_time_secs * (projected / current), 3)}s\"\n",
    "\n",
    "print(f\"Dimensionalité : {dimensionality}, epochs : {epochs}, pourcentage du corpus: {percentage}%\")\n",
    "print(f\"Temps d'exécution : {training_time_secs}s\")\n",
    "print(f\"Temps d'exécution estimé si 100% du corpus était utilisé : {estimate(100, percentage)}\")\n",
    "\n",
    "print(f\"Temps d'exécution estimé si 10 epochs étaient utilisés : {estimate(10, epochs)}\")\n",
    "print(f\"- si 25 epochs: {estimate(25, epochs)}\")\n",
    "print(f\"- si 50 epochs : {estimate(50, epochs)}\")\n",
    "print(f\"- si 100 epochs : {estimate(100, epochs)}\")\n",
    "\n",
    "\n",
    "full_estimated = round(training_time_secs * (100 / percentage) * (100 / epochs), 3)\n",
    "print(f\"Temps d'exécution estimé avec 100 epochs et 100% des documents : {full_estimated}s \")\n",
    "\n",
    "# Avec 100% du corpus et 50 epochs, nous avons un temps d'exécution d'environ 13 minutes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:53:51.041396Z",
     "start_time": "2024-05-12T19:40:54.546665Z"
    }
   },
   "id": "b69bb3c043fd32f0",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save(\"text8_model.bin\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:54:41.127116Z",
     "start_time": "2024-05-12T19:54:37.021274Z"
    }
   },
   "id": "3a97935e9002143c",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation de la taille du modèle : 702.073 Mo\n"
     ]
    }
   ],
   "source": [
    "def print_est_mem(m):\n",
    "    size_estimation = m.estimate_memory()[\"total\"] / 1024 / 1024\n",
    "    print(f\"Estimation de la taille du modèle : {round(size_estimation, 3)} Mo\")\n",
    "\n",
    "print_est_mem(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:55:18.983904Z",
     "start_time": "2024-05-12T19:55:18.979829Z"
    }
   },
   "id": "8299059f7b6efdc3",
   "execution_count": 80
  },
  {
   "cell_type": "markdown",
   "source": [
    "c. Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b881cf8e80820d5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Google News ===\n",
      "PearsonRResult(statistic=0.6238773483165634, pvalue=1.7963227018764457e-39)\n",
      "SignificanceResult(statistic=0.6589215888009288, pvalue=2.5346056459149263e-45)\n",
      "0.0\n",
      "\n",
      "=== text8 ===\n",
      "PearsonRResult(statistic=0.624862501969741, pvalue=1.2590346689054365e-39)\n",
      "SignificanceResult(statistic=0.6658576342425047, pvalue=1.4174213371582874e-46)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Évaluation selon 1g\n",
    "\n",
    "text8_w2v_vectors = model.wv\n",
    "text8_pearson, text8_spearman, text8_oov_ration = text8_w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(\"=== Google News ===\")\n",
    "print(pearson)\n",
    "print(spearman)\n",
    "print(oov_ration)\n",
    "\n",
    "print()\n",
    "print(\"=== text8 ===\")\n",
    "print(text8_pearson)\n",
    "print(text8_spearman)\n",
    "print(text8_oov_ration)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T19:55:28.882093Z",
     "start_time": "2024-05-12T19:55:28.713504Z"
    }
   },
   "id": "3392479f79d5cda3",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de Google News :  0.7320405239459681\n",
      "Score de text8 :  0.31349774866966845\n"
     ]
    }
   ],
   "source": [
    "# Evaluation selon 1h (questions-words.txt)\n",
    "\n",
    "text8_score, text8_section = text8_w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'), dummy4unknown=True)\n",
    "print(\"Score de Google News : \", score)\n",
    "print(\"Score de text8 : \", text8_score)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:01:46.048970Z",
     "start_time": "2024-05-12T19:56:07.064744Z"
    }
   },
   "id": "bc192e6dba6d6ddc",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sur les analogies, le score du modèle entrainé est très faible.\n",
    "# Il peut y avoir plusieurs explications : pour commencer, il est possible que les hyper-paramètres sélectionnés pour Google News soient meilleurs. \n",
    "# Cependant, l'explication la plus plausible serait que les 10^8 caractères de Wikipedia forment des phrases incohérentes telles que \"gate gate gated gates gateway gateway two zero zero zero gauss gaussian\" ou \"of b are orthogonal k e j zero for all k j in b with k j dense span the linear span of b is dense in h we\", qui est du pseudo-code. Le modèle est donc biaisé car les sémantiques ne sont pas juste.\n",
    "# Il est également précisé dans le repo https://github.com/piskvorky/gensim-data?tab=readme-ov-file que ce dataset devrait plutôt être utilisé pour les tests.\n",
    "\n",
    "# Le dataset de Google News étant bien plus cohérent et varié, celui-ci produit de meilleurs résultats. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4602bc6e27b9c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters (413 Mo) fourni en ligne par l’enseignant et appelé wikipedia_augmented.dat. Entraînez un nouveau modèle word2vec sur ce corpus, en précisant aussi la dimension choisie pour le plongement (embedding).\n",
    "• Utilisez la classe Text8Corpus() pour charger le corpus et pour faire la tokenisation et la segmentation en phrases.\n",
    "• Combien de temps prend l’entraînement ?\n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1ab5c9d1b6496db"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Text8Corpus\n",
    "augmented_corpus = Text8Corpus(\"./corpus/wikipedia_augmented.dat\")\n",
    "aug_docs_all = [d for d in augmented_corpus]\n",
    "aug_count_docs = len(aug_docs_all)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:07:33.249787Z",
     "start_time": "2024-05-12T20:07:26.050287Z"
    }
   },
   "id": "64fe41c728411c23",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle augmenté ...\n",
      "Dimensionalité : 300, epochs : 25, pourcentage du corpus: 100%\n",
      "Temps d'exécution : 1564.783s\n",
      "Temps d'exécution estimé si 100% du corpus était utilisé : 1564.783s\n",
      "Temps d'exécution estimé si 10 epochs étaient utilisés : 312.957s\n",
      "- si 25 epochs: 782.391s\n",
      "- si 50 epochs : 1564.783s\n",
      "- si 100 epochs : 3129.566s\n",
      "Temps d'exécution estimé avec 100 epochs et 100% des documents : 6259.132s \n"
     ]
    }
   ],
   "source": [
    "# Prend seulement x% des phrases du corpus augmenté\n",
    "print(\"Entrainement du modèle augmenté ...\")\n",
    "\n",
    "aug_percentage = 100\n",
    "aug_docs_to_take = int((aug_count_docs / (100 / aug_percentage)))\n",
    "aug_docs = aug_docs_all[:aug_docs_to_take]\n",
    "\n",
    "aug_epochs = 25\n",
    "aug_dimensionality = 300\n",
    "\n",
    "aug_start = time.time()\n",
    "aug_model = Word2Vec(sentences=aug_docs,\n",
    "                 vector_size=aug_dimensionality,\n",
    "                 workers=12,\n",
    "                 min_count=1,\n",
    "                 epochs=aug_epochs)\n",
    "aug_end = time.time()\n",
    "aug_training_time_secs = round(aug_end - aug_start, 3)\n",
    "\n",
    "def aug_estimate(projected, current):\n",
    "    return f\"{round(aug_training_time_secs * (projected / current), 3)}s\"\n",
    "\n",
    "print(f\"Dimensionalité : {aug_dimensionality}, epochs : {aug_epochs}, pourcentage du corpus: {aug_percentage}%\")\n",
    "print(f\"Temps d'exécution : {aug_training_time_secs}s\")\n",
    "print(f\"Temps d'exécution estimé si 100% du corpus était utilisé : {aug_estimate(100, aug_percentage)}\")\n",
    "\n",
    "print(f\"Temps d'exécution estimé si 10 epochs étaient utilisés : {aug_estimate(10, aug_epochs)}\")\n",
    "print(f\"- si 25 epochs: {aug_estimate(25, aug_epochs)}\")\n",
    "print(f\"- si 50 epochs : {aug_estimate(50, aug_epochs)}\")\n",
    "print(f\"- si 100 epochs : {aug_estimate(100, aug_epochs)}\")\n",
    "\n",
    "\n",
    "aug_full_estimated = round(aug_training_time_secs * (100 / aug_percentage) * (100 / aug_epochs), 3)\n",
    "print(f\"Temps d'exécution estimé avec 100 epochs et 100% des documents : {aug_full_estimated}s \")\n",
    "\n",
    "# Avec 100% du corpus et 25 epochs, nous avons un temps d'exécutions d'environ 25 minutes.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:34:58.968519Z",
     "start_time": "2024-05-12T20:08:54.175426Z"
    }
   },
   "id": "532ed93a16ccbd4e",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation de la taille du modèle : 1464.749 Mo\n"
     ]
    }
   ],
   "source": [
    "print_est_mem(aug_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:39:50.235642Z",
     "start_time": "2024-05-12T20:39:50.232498Z"
    }
   },
   "id": "3a7b62be523151ce",
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "source": [
    "e. Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ? Pour quelle raison ?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b751c0907f78875"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== text8 ===\n",
      "PearsonRResult(statistic=0.624862501969741, pvalue=1.2590346689054365e-39)\n",
      "SignificanceResult(statistic=0.6658576342425047, pvalue=1.4174213371582874e-46)\n",
      "0.0\n",
      "=== text8 augmenté ===\n",
      "PearsonRResult(statistic=0.5281846908809424, pvalue=9.395485951742592e-27)\n",
      "SignificanceResult(statistic=0.549538782656594, pvalue=3.0449829069408257e-29)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Évaluation selon 1g\n",
    "aug_text8_w2v_vectors = aug_model.wv\n",
    "aug_text8_pearson, aug_text8_spearman, aug_text8_oov_ration = aug_text8_w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(\"=== text8 ===\")\n",
    "print(text8_pearson)\n",
    "print(text8_spearman)\n",
    "print(text8_oov_ration)\n",
    "\n",
    "\n",
    "print(\"=== text8 augmenté ===\")\n",
    "print(aug_text8_pearson)\n",
    "print(aug_text8_spearman)\n",
    "print(aug_text8_oov_ration)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:39:58.297865Z",
     "start_time": "2024-05-12T20:39:58.080992Z"
    }
   },
   "id": "8de0d4af51122cbc",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de text8 :  0.31349774866966845\n",
      "Score de text8 augmenté :  0.3905546459271388\n"
     ]
    }
   ],
   "source": [
    "# Evaluation selon 1f\n",
    "\n",
    "aug_text8_score, aug_text8_section = aug_text8_w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'), dummy4unknown=True)\n",
    "print(\"Score de text8 : \", text8_score)\n",
    "print(\"Score de text8 augmenté : \", aug_text8_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:48:06.127254Z",
     "start_time": "2024-05-12T20:40:37.178383Z"
    }
   },
   "id": "5b7565c30122fe7a",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Le score est légèrement meilleur car l'ajout des données de Reuters permet de contrebalancer les problèmes énoncés au point 2c. Il y a plus de phrases cohérentes et variées et, ainsi, le modèle est meilleur mais pas parfait. Il faudrait retirer la partie de Wikipédia et garder uniquement la partie de Reuters afin de confirmer ces dires, tout en tenant en compte le fait que Reuters est orienté économie alors que Google News est plus généraliste."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fdec7abcf3a9766"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
